{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as date\n",
    "import IPython\n",
    "import IPython.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sklearn\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"/Users/haris/Desktop/Capstone2(eCommerce)/dataset/ecommerceDataset.csv\"\n",
    "column_name = [\"category\",\"description\"]\n",
    "df = pd.read_csv(URL, names=column_name)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50425 entries, 0 to 50424\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   category     50425 non-null  object\n",
      " 1   description  50424 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 788.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: \n",
      " (50425, 2)\n",
      "NA values: \n",
      " category       0\n",
      "description    1\n",
      "dtype: int64\n",
      "Duplicated: \n",
      " 0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "50420     True\n",
      "50421     True\n",
      "50422     True\n",
      "50423     True\n",
      "50424     True\n",
      "Length: 50425, dtype: bool\n",
      "Categories: category\n",
      "Household                 19313\n",
      "Books                     11820\n",
      "Electronics               10621\n",
      "Clothing & Accessories     8671\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \\n\", df.shape)\n",
    "print(\"NA values: \\n\", df.isna().sum())\n",
    "print(\"Duplicated: \\n\",df.duplicated())\n",
    "print(\"Categories:\",df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category       0\n",
       "description    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39330</th>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category description\n",
       "39330  Clothing & Accessories         NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"description\"].isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category       0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace= True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to integer using labelencoder\n",
    "# Separate feature and label\n",
    "feature = df['description'].values\n",
    "label = df['category'].values\n",
    "\n",
    "#(B) Perform label encoding to the category column\n",
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "label_encoded = label_encoder.fit_transform(label)\n",
    "label_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-val-test split\n",
    "import sklearn.model_selection\n",
    "seed= 42\n",
    "\n",
    "x_train,x_split,y_train,y_split = sklearn.model_selection.train_test_split(feature,label_encoded,train_size=0.7,random_state=seed)\n",
    "x_val,x_test,y_val,y_test = sklearn.model_selection.train_test_split(x_split,y_split,train_size = 0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35296,)\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7564,)\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape)\n",
    "print(x_val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. NLP \n",
    "# Tokenization layer\n",
    "\n",
    "tokenizer = keras.layers.TextVectorization(max_tokens=5000, output_sequence_length=200) #train layer\n",
    "tokenizer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Acer 18.5 inch (46.99 cm) LED Monitor - EB192Q (Black) Specifications LED 18.5 '' ACER EB192Qb (B). Brand ACER Model EB192Qb Response Time 5 ms Max. Resolution 1366x768 @ 60Hz Contrast Ratio 100 million: 1 (ACM). Brightness 200 nits (cd / m2). Display 18.5 inch Color System 16.7 m POWER Supply (100V-240V): Internal Power Consumption (Off): 0.45W Power Consumption (Sleep): 14W Power Consumption (on): 18W. VGA Port 1 Port.\"\n",
      " 'SOUMIK ELECTRICALS 5-inch Subwoofer with Maximum 4 ohm(100 W) Thisb product is from the brand SOUMIK ELECTRICALS it presents a 5 Inch subwoofer with maximum 4 ohm and comes with 100W. Use in your home theatre.']\n",
      "tf.Tensor(\n",
      "[[3365 4947  173    1  147  152  622    1   55  595  152 4947 3365    1\n",
      "  1613  151 3365  535    1 1478   61  105 1551  739  649    1    1 1619\n",
      "  1972  115 1539   36    1 1495 1270    1 1373 3153  259 4947  173   65\n",
      "   146    1  805   59  781    1 1290   59 1111  253    1   59 1111  943\n",
      "     1   59 1111   15    1 1210  377   36  377    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   1    1    1 2745    9  472   91    1  614    1   43   10   17    2\n",
      "   151    1    1   13 1131    6  105  173 2745    9  472   91    1    3\n",
      "    69    9    1   32    8   11   50 3043    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]], shape=(2, 200), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# [FYI] Test how the tokenizer works\n",
    "sample_tokens = tokenizer(x_train[:2])\n",
    "print(x_train[:2])\n",
    "print(sample_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (B) Embedding \n",
    "embedding = keras.layers.Embedding(5000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Model Development\n",
    "\n",
    "model = keras.Sequential()\n",
    "# (A) NLP Layers\n",
    "model.add(tokenizer)\n",
    "model.add(embedding)\n",
    "# (B) RNN \n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(32,return_sequences=False)))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Model Compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 108ms/step - accuracy: 0.8025 - loss: 0.5617 - val_accuracy: 0.9625 - val_loss: 0.1431\n",
      "Epoch 2/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 111ms/step - accuracy: 0.9741 - loss: 0.0983 - val_accuracy: 0.9614 - val_loss: 0.1378\n",
      "Epoch 3/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 107ms/step - accuracy: 0.9823 - loss: 0.0654 - val_accuracy: 0.9685 - val_loss: 0.1184\n",
      "Epoch 4/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 106ms/step - accuracy: 0.9873 - loss: 0.0482 - val_accuracy: 0.9619 - val_loss: 0.1430\n",
      "Epoch 5/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 121ms/step - accuracy: 0.9907 - loss: 0.0342 - val_accuracy: 0.9733 - val_loss: 0.1163\n",
      "Epoch 6/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 112ms/step - accuracy: 0.9931 - loss: 0.0271 - val_accuracy: 0.9705 - val_loss: 0.1375\n",
      "Epoch 7/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 108ms/step - accuracy: 0.9941 - loss: 0.0195 - val_accuracy: 0.9710 - val_loss: 0.1516\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 9. Model Training\n",
    "logpath = \"tensorboard/Ecom/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "tb = keras.callbacks.TensorBoard(logpath)\n",
    "es= keras.callbacks.EarlyStopping(patience=2,verbose=3)\n",
    "\n",
    "# Training\n",
    "history = model.fit(x_train,y_train,validation_data=(x_val,y_val), epochs=10,batch_size=32, callbacks=[tb,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9740 - loss: 0.1299\n",
      "[0.15864120423793793, 0.9703860282897949]\n"
     ]
    }
   ],
   "source": [
    "# Further evaluate with test data\n",
    "\n",
    "evaluation = model.evaluate(x_test,y_test)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test)\n",
    "prediction_index = np.argmax(prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1756\n",
      "           1       0.96      0.98      0.97      1312\n",
      "           2       0.96      0.96      0.96      1560\n",
      "           3       0.98      0.97      0.97      2936\n",
      "\n",
      "    accuracy                           0.97      7564\n",
      "   macro avg       0.97      0.97      0.97      7564\n",
      "weighted avg       0.97      0.97      0.97      7564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_report = classification_report(y_test, prediction_index)\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "#(A) Tokenizer\n",
    "with open('tokenizer.json', 'wb') as f:\n",
    "    pickle.dump(tokenizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(B) Label Encoder\n",
    "with open(\"label_encoder.json\",\"wb\") as f:\n",
    "    pickle.dump(label_encoder,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#(C) Model in .h5\n",
    "keras.models.save_model(model, \"saved_models/Classification.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
